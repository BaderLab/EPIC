{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# EPIC: Elution Profile-based Inference of Protein Complex Membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Welcome to the EPIC predictor Jupyter web service. Please use the Kitematic file organizes to upload the selected elution profiles. The following parameters need to be set in order to run EPIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hideOutput": false,
    "hidePrompt": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "root_dir = os.environ['HOME'] + os.sep + \"work\" + os.sep\n",
    "os.chdir(root_dir + os.sep + \"EPIC\" + os.sep + \"src\" + os.sep)\n",
    "\n",
    "import CalculateCoElutionScores as CS\n",
    "import GoldStandard as GS\n",
    "import utils as utils\n",
    "from ipywidgets import widgets, interact, interactive\n",
    "from IPython.display import HTML, display, Javascript\n",
    "import json, sys, shutil, glob, fileupload\n",
    "\n",
    "#Global paramters for input and output directory. These paramteres need to be changed if you want to run EPIC on local machine instead of Dockers\n",
    "input_dir = root_dir + 'input' + os.sep \n",
    "\n",
    "\n",
    "projects =  []\n",
    "for f in [f.split(os.sep)[-2] for f in glob.glob(input_dir+\"*/\")]:\n",
    "    if not f.endswith(\"out\"):\n",
    "        projects.append(f)\n",
    "\n",
    "\n",
    "\n",
    "def f(**kwargs):\n",
    "    return None\n",
    "\n",
    "directoryName_i = widgets.SelectMultiple(\n",
    "    options=projects,\n",
    "    value=[projects[0]],\n",
    "    description='Input',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "features_i = interactive(f, MI=True, Bayes=True, Euclidean=True, WCC=False, Jaccard=True, PCCN=False, PCC=False, Apex=True)\n",
    "num_cores_i = interactive(f, num_cores=\"1\")\n",
    "clf_i = widgets.RadioButtons(\n",
    "    options=[\"Random forest\", \"SVM\"],\n",
    "    description='Classifier',\n",
    "    disabled=False\n",
    ")\n",
    "target_species_i = interactive(f, target_species=\"taxid i.e. 6239 (Worm)\")\n",
    "mode_i = widgets.RadioButtons(\n",
    "    options=['exp', 'fa', 'comb'],\n",
    "    description='Mode',\n",
    "    disabled=False\n",
    ")\n",
    "fa_source_i = widgets.RadioButtons(\n",
    "    options=['GM', 'STRING', 'FILE'],\n",
    "    description='FA source',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def _handle_upload(change):\n",
    "    w = change['owner']\n",
    "    with open(\"/tmp/\" + w.filename, 'wb') as f:\n",
    "        f.write(w.data)\n",
    "    print('Uploaded to `{}` ({:.2f} kB)'.format(\n",
    "        \"/tmp/\" + w.filename, len(w.data) / 2**10))\n",
    "    \n",
    "fa_file = fileupload.FileUploadWidget()\n",
    "fa_file.observe(_handle_upload, names='data')\n",
    "\n",
    "    \n",
    "ref_file = fileupload.FileUploadWidget()\n",
    "ref_file.observe(_handle_upload, names='data')\n",
    "\n",
    "# stdout for debug\n",
    "#print input_dir\n",
    "#print projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "## Input directory\n",
    "When starting the docker you linked one of your local folders with this docker image. This pipeline considers this folder as the input and output folder. In this folder EPIC expects a folder for each project, where each project fodler contains one elution profile file for each co-fractionation experiment. The elution profile file is a tab separated file where the first collumn contains a protein ID and each susequent collumn contains protein value for each fraction, and the file has one row for each protein. Additionally the file has an header line which contains the name of each feraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(directoryName_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Feature slection:\n",
    "Please select which co-elution features should be used to generate the co-eluton network. We recommend using MI, Bayes, PCCN, and Apex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if sum([features_i.kwargs[feature_name] for feature_name in ['PCC', 'Jaccard', 'Apex', 'MI', 'Euclidean',  'WCC', 'Bayes', 'PCCN'] ])==0:\n",
    "    print \"Feature selection is empty! Please select at least one Feature\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Num cores\n",
    "Number of cores that can be used to calculate co-elution scores. Increasing this number reduces run time if the docher and the machine has multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(num_cores_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Classifier:\n",
    "Here you can select the classifier used to generate the co-elution profiles. EPIC supports both SVM and random forest. We recommend to use random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(clf_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Reference data:\n",
    "Here you can either supply an taxid for automatic generation of a reference, or upload a selected set of reference complexes. Please note automatic reference data gereneration is only supported by Uniprot IDs, and the format for the supplied reference complexes is one complex per line, in which the line contains all the cluster's member IDs separated by tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(target_species_i)\n",
    "display(ref_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "target_taxid = target_species_i.kwargs['target_species']\n",
    "if target_taxid == \"taxid i.e. 6239 (Worm)\" and ref_file.filename==\"\":\n",
    "    print \"Please supply either target taxid or reference cluster file\"\n",
    "if target_taxid != \"taxid i.e. 6239 (Worm)\" and ref_file.filename!=\"\":\n",
    "    print \"You gave both reference file and target taxid please choose only one\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### Mode:\n",
    "The mode which EPIC schould be run with. The supported modes are:  experiment only (exp), functional annotation only (fa), both (comb). We suggest to use experiment only when wanting to run EPIC without introducing functional annotation bias into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(mode_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Functional annotation data\n",
    "Please select wich source for functional annotaiton to use. The user can eitehr autoamtically generate functional annotation from GeneMania (GM), or STRING. Alternativly, the user can suplly his own functional annotation data as falt file. In case the the mode is experimental only (exp, in mode selection), then this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(fa_source_i)\n",
    "display(fa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if fa_source_i.value != \"FILE\" and fa_file.filename!=\"\":\n",
    "    print \"Selected %s as functional annotation, but still uploaded functional annotation file\" % fa_source_i.value\n",
    "if fa_source_i.value == \"FILE\" and fa_file.filename==\"\":\n",
    "    print \"Selected file for functional annotation data but no file has been uploaded, please ulpad functional annotation file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "featuer_selection = [features_i.kwargs[feature_name] for feature_name in ['PCC', 'Jaccard', 'Apex', 'MI', 'Euclidean',  'WCC', 'Bayes', 'PCCN'] ]\n",
    "num_cores = int(num_cores_i.kwargs['num_cores'])\n",
    "name = directoryName_i.value[0]\n",
    "anno_source = fa_source_i.value\n",
    "mode = mode_i.value\n",
    "input_dir = root_dir + 'input' + os.sep  + name\n",
    "output_dir = root_dir + 'input' + os.sep + name + \"_out\"\n",
    "\n",
    "if os.path.exists(output_dir) == False: \n",
    "    os.mkdir(output_dir)\n",
    "#else:\n",
    " #   print \"Output dir already exists and removing content\"\n",
    "    #    shutil.rmtree(output_dir)\n",
    "  #  os.mkdir(output_dir)\n",
    "    \n",
    "output_dir += os.sep + \"Out\"\n",
    "target_taxid = target_species_i.kwargs['target_species']\n",
    "use_rf = clf_i.value != 'SVM'\n",
    "if use_rf:\n",
    "    output_dir += \".rf\"\n",
    "else:\n",
    "    output_dir += \".svm\"\n",
    "    \n",
    "use_ref_file = False\n",
    "ref_file_loc = \"/tmp/\" + ref_file.filename\n",
    "if ref_file.filename !=\"\": use_ref_file = True\n",
    "     \n",
    "use_fa_file = False\n",
    "fa_file_loc = \"/tmp/\" + fa_file.filename\n",
    "if fa_file.filename !=\"\": use_fa_file = True\n",
    "    \n",
    "#Create feature combination\n",
    "all_scores = [CS.Pearson(), CS.Jaccard(), CS.Apex(), CS.MutualInformation(2), CS.Euclidiean(), CS.Wcc(), CS.Bayes(3), CS.Poisson(5)]\n",
    "this_scores = []\n",
    "for i, selection in enumerate(featuer_selection):\n",
    "\tif selection: this_scores.append(all_scores[i])    \n",
    "    \n",
    "#Stdout for debug\n",
    "#print num_cores\n",
    "#print(featuer_selection)\n",
    "#print use_rf\n",
    "#print target_taxid\n",
    "#print input_dir\n",
    "#print output_dir\n",
    "#print mode\n",
    "#print anno_source\n",
    "#print use_ref_file\n",
    "#print use_fa_file\n",
    "#print this_scores\n",
    "#print ref_file_loc\n",
    "#print fa_file_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "## Initializing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Initialize CLF\n",
    "clf = CS.CLF_Wrapper(num_cores, use_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Loading Elution profile data\n",
    "EPIC loads in the elution data and removes proteins that are observed in exactly one fraction per experiment. Optimally the percentage of removed proteins should not exceed 50% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# load elution data\n",
    "print input_dir\n",
    "foundprots, elution_datas = utils.load_data(input_dir, this_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Generating reference data\n",
    "In this step EPIC automatically generate reference data taken from CORUM, Intact, and GO. We recommend the final number of complexes to be at least 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Generate reference data set\n",
    "import GoldStandard as GS\n",
    "all_gs = \"\"\n",
    "if use_ref_file:\n",
    "    clusters = GS.Clusters(need_to_be_mapped=False)\n",
    "    clusters.read_file(ref_file_loc)\n",
    "    clusters.remove_proteins(foundprots)\n",
    "    all_gs = GS.Goldstandard_from_Complexes(\"All\")\n",
    "    all_gs.complexes = clusters\n",
    "    all_gs.make_pos_neg_ppis()\n",
    "    print \"Loaded %i complexes from file\" % (len(all_gs.complexes.complexes))\n",
    "else:\n",
    "    all_gs = utils.create_goldstandard(target_taxid, foundprots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Calculating co-elution scores\n",
    "This is the most time intensive step of EPIC and on average take 20 min per co-elution score per experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Caculating scores\n",
    "scoreCalc = CS.CalculateCoElutionScores(this_scores, elution_datas, output_dir + \".scores.txt\", num_cores=num_cores)\n",
    "#scoreCalc.calculate_coelutionDatas(all_gs)\n",
    "# For debug readin precalculated co-elution scores\n",
    "scoreCalc.readTable(output_dir + \".scores.txt\", all_gs)\n",
    "\n",
    "all_gs.positive = set(all_gs.positive & set(scoreCalc.ppiToIndex.keys()))\n",
    "all_gs.negative = set(all_gs.negative & set(scoreCalc.ppiToIndex.keys()))\n",
    "all_gs.rebalance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if mode != \"exp\":\n",
    "    functionalData = utils.get_FA_data(anno_source, fa_file_loc)\n",
    "    print \"Dimension of fun anno \" + str(functionalData.scores.shape)\n",
    "    tmp_sc = copy.deepcopy(scoreCalc)\n",
    "    tmp_sc.add_fun_anno(functionalData)\n",
    "    utils.cv_bench_clf(tmp_sc, clf, all_gs, output_dir)\n",
    "else:\n",
    "    utils.cv_bench_clf(scoreCalc, clf, all_gs, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Classifier evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Precision and recall values for various classifier confidence cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=output_dir + \".cutoff.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "Image(filename=output_dir + \".pr.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(filename=output_dir + \".roc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Prediction protein interaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Predict protein interaction\n",
    "network =  utils.make_predictions(scoreCalc, mode, clf, all_gs, functionalData)\n",
    "\n",
    "final_network = []\n",
    "for PPI in network:\n",
    "    items = PPI.split(\"\\t\")\n",
    "    if float(items[2]) >= 0.68:\n",
    "        final_network.append(PPI)\n",
    "\n",
    "network = final_network\n",
    "            \n",
    "outFH = open(\"%s.%s.pred.txt\" % (output_dir, mode), \"w\")\n",
    "print >> outFH, \"\\n\".join(network)\n",
    "outFH.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Read network for debugging\n",
    "network = []\n",
    "netFH = open(\"%s.%s.pred.txt\" % (output_dir, mode))\n",
    "for line in netFH:\n",
    "    line = line.rstrip()\n",
    "    network.append(line)\n",
    "netFH.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Prediction protein clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Predicting clusters\n",
    "utils.predict_clusters(\"%s.%s.pred.txt\" % (output_dir, mode), \"%s.%s.clust.txt\" % (output_dir, mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Clustering evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import GoldStandard as GS\n",
    "# Evaluating predicted clusters\n",
    "pred_clusters = GS.Clusters(False)\n",
    "pred_clusters.read_file(\"%s.%s.clust.txt\" % (output_dir, mode))\n",
    "s, h = utils.clustering_evaluation(all_gs.complexes, pred_clusters, \"\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Uncomment these lines in order to update the Cytoscape.js extension\n",
    "# ====================================================================\n",
    "import notebook.nbextensions\n",
    "notebook.nbextensions.install_nbextension('https://cdnjs.cloudflare.com/ajax/libs/cytoscape/2.7.14/cytoscape.js', user=True)\n",
    "# ===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "// Use the Cytoscape.js extension and make cytoscape global\n",
    "require(['nbextensions/cytoscape'], function (cytoscape) {\n",
    "    window.cytoscape = cytoscape;\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "all_eData_head, all_eData_scores = utils.elutionDatas_to_treeview(elution_datas, foundprots)\n",
    "clust_json, clust_edges, clust_nodes = utils.clusters_to_json(pred_clusters, network, all_eData_head, all_eData_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Clustering network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "clust_js = utils.json_to_cy_js(\"clust_cy\", clust_json)\n",
    "clust_cy_div = \"\"\"<div id='clust_cy' style=\"width: 100%; height: 500px; background: #f0f0f0;\"></div>\"\"\"\n",
    "display(HTML(clust_cy_div))\n",
    "Javascript(clust_js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Sending cluster data to running cytoscape instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "BASE, DATA, HEADERS = utils.prep_network_for_cy(clust_nodes, clust_edges)\n",
    "res = requests.delete(BASE + 'session')\n",
    "json.dumps(res.json())\n",
    "req = requests.post(BASE + 'networks', data=DATA, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "36a102645923415fba129f8995eab601": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "533322dc1add4807bb5e3298a2ffbb2a": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "5ef9b50fad144341b001325facfdcf88": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "684ce09c9a87426e9096dc77cbbbc3fd": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "a833a3e96fb34af1a78b41240b54ffb2": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "b8bcb44634f146f58e0bb1ec49859700": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "fe8bd73b6464414cb475177007946e7f": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
