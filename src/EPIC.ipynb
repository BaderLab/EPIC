{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# EPIC: Elution Profile-based Inference of Protein Complex Membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Welcome to the EPIC predictor Jupyter web service. Please use the Kitematic file organizes to upload the selected elution profiles. The following parameters need to be set in order to run EPIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "root_dir = os.environ['HOME'] + os.sep + \"work\" + os.sep\n",
    "os.chdir(root_dir + os.sep + \"EPIC\" + os.sep + \"src\" + os.sep)\n",
    "\n",
    "import CalculateCoElutionScores as CS\n",
    "import GoldStandard as GS\n",
    "import utils as utils\n",
    "from ipywidgets import widgets, interact, interactive\n",
    "from IPython.display import HTML, display, Javascript\n",
    "import json, sys, shutil, glob, fileupload\n",
    "\n",
    "#Global paramters for input and output directory. These paramteres need to be changed if you want to run EPIC on local machine instead of Dockers\n",
    "input_dir = root_dir + 'input' + os.sep \n",
    "\n",
    "\n",
    "projects =  []\n",
    "for f in [f.split(os.sep)[-2] for f in glob.glob(input_dir+\"*/\")]:\n",
    "    if not f.endswith(\"out\") and not f.endswith(\"fa_files\"):\n",
    "        projects.append(f)\n",
    "\n",
    "\n",
    "\n",
    "def f(**kwargs):\n",
    "    return None\n",
    "\n",
    "directoryName_i = widgets.SelectMultiple(\n",
    "    options=projects,\n",
    "    value=[projects[0]],\n",
    "    description='Input',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "features_i = interactive(f, MI=True, Bayes=True, Euclidean=True, WCC=False, Jaccard=True, PCCN=False, PCC=False, Apex=True)\n",
    "num_cores_i = interactive(f, num_cores=\"1\")\n",
    "clf_i = widgets.RadioButtons(\n",
    "    options=[\"Random forest\", \"SVM\"],\n",
    "    description='Classifier',\n",
    "    disabled=False\n",
    ")\n",
    "target_species_i = interactive(f, target_species=\"taxid i.e. 6239 (Worm)\")\n",
    "mode_i = widgets.RadioButtons(\n",
    "    options=['exp', 'comb'],\n",
    "    description='Mode',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "fa_source_i = widgets.RadioButtons(\n",
    "    options=['GM', 'STRING', 'FILE'],\n",
    "    description='FA source',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def _handle_upload(change):\n",
    "    w = change['owner']\n",
    "    with open(\"/tmp/\" + w.filename, 'wb') as f:\n",
    "        f.write(w.data)\n",
    "    print('Uploaded to `{}` ({:.2f} kB)'.format(\n",
    "        \"/tmp/\" + w.filename, len(w.data) / 2**10))\n",
    "    \n",
    "fa_dir = input_dir+os.sep+\"fa_files\"\n",
    "\n",
    "fa_files = [\"No File\"]\n",
    "\n",
    "if os.path.exists(fa_dir):\n",
    "    for f in [f.split(os.sep)[-1] for f in glob.glob(fa_dir + os.sep + \"*\")]:\n",
    "            fa_files.append(f)\n",
    "\n",
    "            \n",
    "fa_file = widgets.SelectMultiple(\n",
    "    options=fa_files,\n",
    "    value=[fa_files[0]],\n",
    "    description='FA File select',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "    \n",
    "ref_file = fileupload.FileUploadWidget()\n",
    "ref_file.observe(_handle_upload, names='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Input directory\n",
    "When starting the docker you linked one of your local folders with this docker image. This pipeline considers this folder as the input and output folder. In this folder EPIC expects a folder for each project, where each project fodler contains one elution profile file for each co-fractionation experiment. The elution profile file is a tab separated file where the first collumn contains a protein ID and each susequent collumn contains protein value for each fraction, and the file has one row for each protein. Additionally the file has an header line which contains the name of each feraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(directoryName_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Feature slection:\n",
    "Please select which co-elution features should be used to generate the co-eluton network. We recommend using MI, Bayes, PCCN, and Apex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if sum([features_i.kwargs[feature_name] for feature_name in ['PCC', 'Jaccard', 'Apex', 'MI', 'Euclidean',  'WCC', 'Bayes', 'PCCN'] ])==0:\n",
    "    print \"Feature selection is empty! Please select at least one Feature\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Num cores\n",
    "Number of cores that can be used to calculate co-elution scores. Increasing this number reduces run time if the docher and the machine has multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(num_cores_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Classifier:\n",
    "Here you can select the classifier used to generate the co-elution profiles. EPIC supports both SVM and random forest. We recommend to use random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(clf_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Reference data:\n",
    "Here you can either supply an taxid for automatic generation of a reference, or upload a selected set of reference complexes. Please note automatic reference data gereneration is only supported by Uniprot IDs, and the format for the supplied reference complexes is one complex per line, in which the line contains all the cluster's member IDs separated by tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(target_species_i)\n",
    "display(ref_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "target_taxid = target_species_i.kwargs['target_species']\n",
    "if target_taxid == \"taxid i.e. 6239 (Worm)\" and ref_file.filename==\"\":\n",
    "    print \"Please supply either target taxid or reference cluster file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### Mode:\n",
    "The mode which EPIC should be run with. The supported modes are:  experiment only (exp) and experiment with functional annotation (comb). We suggest to use experiment only when wanting to run EPIC without introducing functional annotation bias into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(mode_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Functional annotation data\n",
    "Please select wich source for functional annotaiton to use. The user can eitehr autoamtically generate functional annotation from GeneMania (GM), or STRING. Alternativly, the user can suplly his own functional annotation data as falt file. In case the the mode is experimental only (exp, in mode selection), then this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "display(fa_source_i)\n",
    "display(fa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if fa_source_i.value != \"FILE\" and fa_file.value[0] != \"No File\":\n",
    "    print \"Selected %s as functional annotation, but still uploaded functional annotation file\" % fa_source_i.value\n",
    "if fa_source_i.value == \"FILE\" and fa_file.value[0]==\"No File\":\n",
    "    print \"Selected file for functional annotation data but no file has been uploaded, please ulpad functional annotation file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "featuer_selection = [features_i.kwargs[feature_name] for feature_name in ['PCC', 'Jaccard', 'Apex', 'MI', 'Euclidean',  'WCC', 'Bayes', 'PCCN'] ]\n",
    "num_cores = int(num_cores_i.kwargs['num_cores'])\n",
    "name = directoryName_i.value[0]\n",
    "anno_source = fa_source_i.value\n",
    "mode = mode_i.value\n",
    "\n",
    "input_dir = root_dir + 'input' + os.sep  + name\n",
    "output_dir = root_dir + 'input' + os.sep + name + \"_out\"\n",
    "\n",
    "if os.path.exists(output_dir) == False: \n",
    "    os.mkdir(output_dir)\n",
    "#else:\n",
    " #   print \"Output dir already exists and removing content\"\n",
    "    #    shutil.rmtree(output_dir)\n",
    "  #  os.mkdir(output_dir)\n",
    "    \n",
    "output_dir += os.sep + \"Out\"\n",
    "target_taxid = target_species_i.kwargs['target_species']\n",
    "use_rf = clf_i.value != 'SVM'\n",
    "if use_rf:\n",
    "    output_dir += \".rf\"\n",
    "else:\n",
    "    output_dir += \".svm\"\n",
    "    \n",
    "use_ref_file = False\n",
    "ref_file_loc = \"/tmp/\" + ref_file.filename\n",
    "if ref_file.filename !=\"\": use_ref_file = True\n",
    "     \n",
    "use_fa_file = False\n",
    "fa_file_loc = fa_dir + os.sep + fa_file.value[0]\n",
    "if fa_file.value[0] !=\"No File\": use_fa_file = True\n",
    "    \n",
    "#Create feature combination\n",
    "all_scores = [CS.Pearson(), CS.Jaccard(), CS.Apex(), CS.MutualInformation(2), CS.Euclidiean(), CS.Wcc(), CS.Bayes(3), CS.Poisson(5)]\n",
    "this_scores = []\n",
    "for i, selection in enumerate(featuer_selection):\n",
    "\tif selection: this_scores.append(all_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "## Initializing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Initialize CLF\n",
    "clf = CS.CLF_Wrapper(num_cores, use_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Loading Elution profile data\n",
    "EPIC loads in the elution data and removes proteins that are observed in exactly one fraction per experiment. Optimally the percentage of removed proteins should not exceed 50% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# load elution data\n",
    "#print input_dir\n",
    "foundprots, elution_datas = utils.load_data(input_dir, this_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Generating reference data\n",
    "In this step EPIC automatically generate reference data taken from CORUM, Intact, and GO. We recommend the final number of complexes to be at least 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Generate reference data set\n",
    "import GoldStandard as GS\n",
    "\n",
    "gs_clusters = []\n",
    "all_gs = \"\"\n",
    "if use_ref_file:\n",
    "    gs_clusters.append(GS.FileClusters(ref_file_loc, foundprots))\n",
    "    print \"Loaded complexes from file\"\n",
    "\n",
    "if target_taxid != \"taxid i.e. 6239 (Worm)\":\n",
    "    \n",
    "    if target_taxid != \"6239\":\n",
    "        print \"Loading clusters from GO, CORUM, and Intact\"\n",
    "        gs_clusters.extend(utils.get_reference_from_net(target_taxid))\n",
    "    else:\n",
    "        gs_clusters.append(GS.FileClusters(root_dir + \"WORM/ref_complexes.txt\", foundprots))\n",
    "        print \"Loaded WORM complexes from image reference file in WORM/ref_complexes.txt\"\n",
    "    \n",
    "all_gs = utils.create_goldstandard(gs_clusters, target_taxid, foundprots)\n",
    "    \n",
    "refFH = open(output_dir + \".ref_complexes.txt\", \"w\")\n",
    "for comp in all_gs.complexes.complexes:\n",
    "    print >> refFH, \"%s\\t%s\" % (\",\".join(comp), \",\".join(all_gs.complexes.complexes[comp]))\n",
    "refFH.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Calculating co-elution scores\n",
    "This is the most time intensive step of EPIC and on average take 20 min per co-elution score per experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Caculating scores\n",
    "scoreCalc = CS.CalculateCoElutionScores(this_scores, elution_datas, output_dir + \".scores.txt\", num_cores=num_cores)\n",
    "scoreCalc.calculate_coelutionDatas(all_gs)\n",
    "# For debug readin precalculated co-elution scores\n",
    "#scoreCalc.readTable(output_dir + \".scores.txt\", all_gs)\n",
    "\n",
    "all_gs.positive = set(all_gs.positive & set(scoreCalc.ppiToIndex.keys()))\n",
    "all_gs.negative = set(all_gs.negative & set(scoreCalc.ppiToIndex.keys()))\n",
    "all_gs.rebalance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get functional annotation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "functionalData = \"\"\n",
    "if mode != \"exp\":\n",
    "    if target_taxid == \"6239\":\n",
    "        if anno_source == \"GM\":\n",
    "            functionalData = utils.get_FA_data(\"FILE\", root_dir + \"WORM/genemania_fa_scores.txt\")\n",
    "            print \"loaded genemania data from image\"   \n",
    "        elif anno_source == \"STRING\":\n",
    "            functionalData = utils.get_FA_data(\"FILE\", root_dir + \"WORM/string_fa_scores.txt\")\n",
    "            print \"loaded STRING data from image\"\n",
    "        else:\n",
    "            functionalData = utils.get_FA_data(anno_source, fa_file_loc, os.sep.join(output_dir.split(os.sep)[0:-1]))\n",
    "    else:\n",
    "        functionalData = utils.get_FA_data(anno_source, fa_file_loc, os.sep.join(output_dir.split(os.sep)[0:-1]))    \n",
    "    tmp_sc = copy.deepcopy(scoreCalc)\n",
    "    tmp_sc.add_fun_anno(functionalData)\n",
    "    utils.cv_bench_clf(tmp_sc, clf, all_gs, output_dir, format=\"png\", folds=3)\n",
    "    \n",
    "else:\n",
    "    utils.cv_bench_clf(scoreCalc, clf, all_gs, output_dir, format=\"png\", folds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=output_dir + \".pr.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=output_dir + \".roc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Prediction protein interaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Predict protein interaction\n",
    "network =  utils.make_predictions(scoreCalc, mode, clf, all_gs, functionalData)\n",
    "\n",
    "outFH = open(\"%s.%s.pred.txt\" % (output_dir, mode), \"w\")\n",
    "print >> outFH, \"\\n\".join(network)\n",
    "outFH.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Prediction protein clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Predicting clusters\n",
    "utils.predict_clusters(\"%s.%s.pred.txt\" % (output_dir, mode), \"%s.%s.clust.txt\" % (output_dir, mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Clustering evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import GoldStandard as GS\n",
    "# Evaluating predicted clusters\n",
    "pred_clusters = GS.Clusters(False)\n",
    "pred_clusters.read_file(\"%s.%s.clust.txt\" % (output_dir, mode))\n",
    "s, h = utils.clustering_evaluation(all_gs.complexes, pred_clusters, \"\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Uncomment these lines in order to update the Cytoscape.js extension\n",
    "# ====================================================================\n",
    "import notebook.nbextensions\n",
    "notebook.nbextensions.install_nbextension('https://cdnjs.cloudflare.com/ajax/libs/cytoscape/2.7.14/cytoscape.js', user=True)\n",
    "# ===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "// Use the Cytoscape.js extension and make cytoscape global\n",
    "require(['nbextensions/cytoscape'], function (cytoscape) {\n",
    "    window.cytoscape = cytoscape;\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "all_eData_head, all_eData_scores = utils.elutionDatas_to_treeview(elution_datas, foundprots)\n",
    "clust_json, clust_edges, clust_nodes = utils.clusters_to_json(pred_clusters, network, all_eData_head, all_eData_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Clustering network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "clust_js = utils.json_to_cy_js(\"clust_cy\", clust_json)\n",
    "clust_cy_div = \"\"\"<div id='clust_cy' style=\"width: 100%; height: 500px; background: #f0f0f0;\"></div>\"\"\"\n",
    "display(HTML(clust_cy_div))\n",
    "Javascript(clust_js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Sending cluster data to running cytoscape instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "BASE, DATA, HEADERS = utils.prep_network_for_cy(clust_nodes, clust_edges)\n",
    "res = requests.delete(BASE + 'session')\n",
    "json.dumps(res.json())\n",
    "req = requests.post(BASE + 'networks', data=DATA, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "36a102645923415fba129f8995eab601": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "533322dc1add4807bb5e3298a2ffbb2a": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "5ef9b50fad144341b001325facfdcf88": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "684ce09c9a87426e9096dc77cbbbc3fd": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "a833a3e96fb34af1a78b41240b54ffb2": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "b8bcb44634f146f58e0bb1ec49859700": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "fe8bd73b6464414cb475177007946e7f": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
